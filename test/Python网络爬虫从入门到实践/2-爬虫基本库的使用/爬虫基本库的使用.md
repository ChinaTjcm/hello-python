# 爬虫基本库的使用

## 一、Chrome 抓包详解

        抓包是抓取客户端与远程服务器通信时传递的数据包。Chrome 内置了一套功能强大的
    Web 开发和调试工具，可用来对网站进行调试和分析，用来抓包非常方便。可以通过下面
    的几种方式打开开发者工具。
    （1）在 Chrome 界面按 F12 键。
    （2）右键单击网页空白处，单击检查。
    （3）打开谷歌【开发者工具】

        开发者工具界面中的内容依次如下。
        1. Elements（元素面板）：当前网页的页面结构，在分析所要抓取的节点时会用到，
        而且可以实时修改页面内容，改成自己想要的结果。一个很常用的小技巧是把密
        码输入框 type 的属性由 password 改为 text，这样就可以查看明文密码了。
        2. Console（控制台面板）：记录开发者开发过程中的日志信息，且可以作为与 JS 进
        行交互的命令行 Shell。
        3. Sources（源代码面板）：可以断点调试 JavaScript。
        4. Network（网络面板）：记录从发起网页页面请求 Request 后得到的各种请求资源
        信息（包括状态、资源类型、大小、所用时间等），Web 开发者经常根据这些内容
        进行网络性能优化。
        5. Performance（性能面板）：使用时间轴面板，可以记录或查看网站生命周期内发生
        的各种事件，网站开发者可以根据这些信息进行优化，以提高页面运行时的性能。
        6. Memory（内存面板）：查看 Web 应用或页面的执行时间及内存使用情况。
        7. Application（应用面板）：记录网站加载的所有资源信息，包括存储数据（Local 
        Storage、Session Storage、IndexedDB、Web SQL、Cookies）、缓存数据、字体、
        图片、脚本、样式表等。
        8. Security（安全面板）：判断当前网页是否安全。
        9. Audits（审核面板）：对当前网页进行网络利用情况、网页性能方面的诊断，并给
        出一些优化建议，比如列出所有没有用到的 CSS 文件。

        进行抓包时，主要查看 Network 选项卡，Network 选项卡由如图 2.3 所示的四部分窗格组成。

### 1.1 Controls 面板

    ...

### 1.2 Filter

    ···

### 1.3 Request Table

    ···

## 二、urllib 库详解

    注意 python 2、3 的区别
    4 个模块：
    (1) request 模块：打开和浏览 URL 中的内容
    (2) error 模块：包含 urllib.request 发生的错误或异常
    (3) parse 模块：解析 URL
    (4) robotparser 模块：解析 robots.txt 文件
    



